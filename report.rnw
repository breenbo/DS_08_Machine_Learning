\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left
\usepackage[english]{babel} % Specify a different language here - english by default
\usepackage{float}
\usepackage{parskip} % no paragraph indent
\usepackage[section]{placeins} % to have FloatBarrier against float
\usepackage{lipsum} % Required to insert dummy text. To be removed otherwise
\usepackage{tabularx}
\usepackage{tabulary}

%-----------------------------------------------------------------------
%	COLUMNS
%-----------------------------------------------------------------------

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

%-----------------------------------------------------------------------
%	COLORS
%-----------------------------------------------------------------------

\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

%-----------------------------------------------------------------------
%	HYPERLINKS
%-----------------------------------------------------------------------

\usepackage{hyperref} % Required for hyperlinks
\hypersetup{hidelinks,colorlinks,breaklinks=true,urlcolor=color2,citecolor=color1,linkcolor=color1,bookmarksopen=false,pdftitle={Title},pdfauthor={Author}}

%-----------------------------------------------------------------------
%	ARTICLE INFORMATION
%-----------------------------------------------------------------------

\JournalInfo{17th January 2016} % Journal information
\Archive{} % Additional notes (e.g. copyright, DOI, review/research article)

\PaperTitle{Machine Learning Project - Prediction of barbell lifts} % Article title

\Authors{Bruno \textsc{Berrehuel}*} % Authors
\affiliation{*\textbf{Corresponding author}: METTRE PROFIL LINKED IN} % Corresponding author

\Keywords{Machine Learning --- Predictive Modeling --- Monitored fit exercices} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

%-----------------------------------------------------------------------
%	ABSTRACT
%-----------------------------------------------------------------------

\Abstract{ Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  This report predicts the manner in which people did the exercises, based on data from accelerometers on the belt, forearm, arm, and dumbell.  The detailed results are shown in table~\ref{totresume}, with very good accuracy.  In this case, variables with NA aren't necessary to fit a good prediction model.  
Further fine tuning could be done on the model, but this will not be seen in this report.
    

\emph{A good model should have good accuracy for few computation time. So I recommand using the Bagged Tree model as shown in figure~\ref{fig:plotFour}. It is possible to predict and survey, not only \emph{if} people do exercices, but most of it \emph{how} they do it.}}


%-----------------------------------------------------------------------

\begin{document}

\flushbottom % Makes all text pages the same height
\maketitle % Print the title and abstract box
\tableofcontents % Print the contents section
\thispagestyle{empty} % Removes page numbering from the first page

%-----------------------------------------------------------------------
%	FUNCTIONS AND MAIN RESULTS
%-----------------------------------------------------------------------
<<loadData, warning=FALSE, echo=FALSE, message=FALSE>>=
library(doMC)
registerDoMC(cores=6) # parallel computation

library(data.table)
library(xtable)

# Downloading files if they don't already exist
if(!file.exists("datas/trainDatas.csv")){
    download.file("https://d396qusza40orc.cloudfront.net/
                  predmachlearn/pml-training.csv", "datas/trainDatas.csv")}
if(!file.exists("datas/testDatas.csv")){
    download.file("https://d396qusza40orc.cloudfront.net/
                  predmachlearn/pml-testing.csv", "datas/testDatas.csv")}

datas <- fread("datas/trainDatas.csv", na.strings=c("NA","","#DIV/0!"))
quizz <- fread("datas/testDatas.csv", na.strings=c("NA","","#DIV/0!"))
@
<<nadist, echo=FALSE>>=
# remove unwanted columns
clean1 <- subset(datas, select = c(-1:-7))
# look at NA distribution in predictors
colNA <- apply(clean1, 2, is.na) 
meanNA <- apply(colNA, 2, mean)
index <- 1:ncol(colNA)
meanNA <- cbind(meanNA,index)
meanNA <- data.frame(meanNA)
@
<<namean, echo=FALSE>>=
# Calculate mean of NA in predictors
naSums <- colSums(is.na(clean1))
dirty <- subset(clean1, select = (naSums!=0))
dirtyColNA <- apply(dirty, 2, is.na)
dirtyMeanNA <- apply(dirtyColNA, 2, mean)
resultsNA <- data.frame(mean=mean(dirtyMeanNA), sd=sd(dirtyMeanNA))
sumNA <- summary(dirtyMeanNA)
mini <- round(min(dirtyMeanNA),4)
maxi <- round(max(dirtyMeanNA),4)
moy <- round(mean(dirtyMeanNA),4)
sdev <- round(sd(dirtyMeanNA),4)
sumNA <- data.frame(min=mini, mean=moy, max=maxi, sd=sdev)
# Remove all predictors with NA from the dataset
# clean is no the reference dataset.
clean <- subset(clean1, select = (naSums==0))
@
<<functions, echo=FALSE>>=
library(caret)
seed <- 27
# create quickview datasets
set.seed(seed)
quickTrain <- createDataPartition(clean$classe, p=0.05)[[1]]
quickview <- clean[quickTrain,]

# functions to automate model test
algo <- function(algo, datas, seed=27, metrics="Accuracy", 
                 preprocess=c("center","scale"), controlMeth="repeatedcv",
                 controlNum=10, controlRep=3,...) {
    # function to fit one algorithm  algo on datas, with possibility to choose 
    # trainControl, metric, preProc, seed. Datas are centered and scaled by default.
    # add computation time for training at the end of the result.
    require(caret)
    set.seed(seed)
    # set trainControl
    control <- trainControl(method=controlMeth, number=controlNum, 
                            repeats=controlRep)
    # set the timer
    ptm <- proc.time()
    fitAlgo <- train(classe~., data=datas, method=algo, metric=metrics, 
                     preProc=preprocess, trControl=control,...)
    # record computation time
    timeFit <- proc.time()-ptm
    # store results in a list : x[[y]][[1]] give model, 
    # x[[y]][[2]] give computation time
    list(fitAlgo, timeFit[3])
}

accuAlgo <- function(fitAlgo){
    # research of the best accuracy
    accuracy <- max(fitAlgo[[1]]$results$Accuracy)
    # research of SD for this accuracy
    indAcc <- which.max(fitAlgo[[1]]$results$Accuracy)
    # accuracySD <- fitAlgo[[1]]$results$AccuracySD[indAcc]
    meth <- fitAlgo[[1]]$method
    # store results in data.frame
    res <- data.frame(Accuracy = accuracy, Time=fitAlgo[[2]], method=meth)
    row.names(res) <- fitAlgo[[1]]$modelInfo$label
    res
}

sampleAccu <- function(fitAlgo){
    # store all accuracies computed with the controlTrain in order to boxplot 
    # and t.test them
    sampleaccu <- fitAlgo[[1]]$resample$Accuracy
    resu <- data.frame(sampleaccu)
    names(resu) <- fitAlgo[[1]]$modelInfo$label
    resu
}

multiAlgo <- function(multi, datas, seed=27, metrics="Accuracy",
                      preprocess=c("center","scale"),
                      controlMeth="repeatedcv", controlNum=10,
                      controlRep=3){
    # function to test several model and store results in a list
    resultats <- list()
    for (i in multi){
        resultats[match(i,multi)] <- list(algo(datas=datas, algo=i, 
                                               seed=seed, metrics=metrics,
                                               preprocess=preprocess,
                                               controlMeth=controlMeth,
                                               controlNum=controlNum,
                                               controlRep=controlRep))
    }
    resultats
}

multiAccu <- function(multi){
    # function to present accuracy, sd and computation time in a ordered dataframe
    # use accuAlgo function to retrieve info for each element of the list
    lapp <- lapply(multi, function(y) accuAlgo(y))
    # loop to store info in table
    leng <- length(multi)
    comput <- NULL
    for (i in 1:leng){
        comput <- rbind(comput,lapp[[i]])
    }
    # order the table on decreasing accuracy
    comput[order(comput$Accuracy, decreasing=T),]
}

multiSampleAccu <- function(multi){
    # function to present the 30 accurracies for each model,
    # in order to plot or t.test them.
    lap <- lapply(multi, function(y) sampleAccu(y))
    len <- length(multi)
    # store in matrix with nrow = nbFold*nbRepeats from trainControl
    compute <- matrix(nrow=nrow(lap[[1]]))
    for (i in 1:len){
        compute <- cbind(compute,lap[[i]])
    }
    compute <- subset(compute, select=c(-1))
    moy <- apply(compute, 2, mean)
    compute <- rbind(compute, moy)
    ordre <- order(compute[31,], decreasing=T)
    compute <- compute[,ordre]
    compute
}

@
<<testAllModels, echo=FALSE, message=FALSE, warning=FALSE, results="hide", cache=TRUE>>=
modelAll <- c("bagFDA", "C5.0", "dnn", "earth", "gbm", "gpls", "hdda",
              "lda", "knn", "mda", "nb", "nnet", "parRF", "pam",
              "pda", "rf", "rpart", "snn", "svmLinear", "svmRadial",
              "treebag")

fitAll <- multiAlgo(modelAll, datas=quickview)
orderAllMethod <- as.character(multiAccu(fitAll)$method)
@
<<bestFive, echo=FALSE, message=FALSE, warning=FALSE, results="hide", cache=TRUE>>=
#bestFive <- c("C5.0", "rf", "parRF", "gbm", "treebag")
bestFive <- orderAllMethod[1:5]
fitFive <- multiAlgo(bestFive, datas=clean)
@
%-----------------------------------------------------------------------
%	ARTICLE CONTENTS
%-----------------------------------------------------------------------

%##################################################
\section*{Introduction} % The \section*{} command stops section numbering
%##################################################

\addcontentsline{toc}{section}{Introduction} % Adds this section to the table of contents

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.


Six candidates were asked to perform barbell lifts correctly and incorrectly in 5 different ways.
Results in the datasets are classified in 5 classes, according to how the exercises are done\footnote{Source : \url{http://groupware.les.inf.puc-rio.br/har}} :
\begin{itemize}[noitemsep] % [noitemsep] removes whitespace between the items for a compact look
    \item Class A : exactly according to the specification
    \item Class B : throwing the elbows to the front 
    \item Class C : lifting the dumbbell only halfway 
    \item Class D : lowering the dumbbell only halfway 
    \item Class E : throwing the hips to the front.
\end{itemize}


%##################################################
\section{Dealing with datas}
%##################################################

\subsection{Exploratory Analysis}

There are \Sexpr{dim(datas)[2]} potentials predictors, for \Sexpr{dim(datas)[1]} observations.
After a look on the structures of the data presented in appendix, the following columns can be removed because they have no added value for predictive model purpose : V1, user\_name, timestamps and windows columns.


There are still \Sexpr{dim(clean1)[2]} potentials predictors, and it seems to have several NAs in the dataset, and they have to be managed.


\subsection{Dealing with NA's}
There is no data without NA's. So it is necessary to view the distribution of the NA's, and find a solution to deal with them.
<<plotna2, echo=FALSE, fig.cap="Distribution of NA in predictors", out.height="5cm", fig.height=3>>=
# Plot the distribution
par(mar=c(4,4,1,2))
hist(meanNA$meanNA, main="", breaks=75, col="blue",
     xlab="mean of NA")
@
<<plotnamean, echo=FALSE, results="asis">>=
# Print the summary in nice table
print.xtable(xtable(sumNA,
                    caption="Summary for mean of NA in predictors 
                    with NA",
                    digits=4, label="namean"), include.rownames=F)
@

\FloatBarrier
As seen on figure~\ref{fig:plotna2} and the table~\ref{namean}, there are only two cases for predictors with NA :
\begin{itemize}[noitemsep]
    \item no NA in the predictor
    \item a lot of NA in the predictor, more than \Sexpr{round(sumNA[1],3)*100}\%.
\end{itemize}


\emph{Columns can be safely removed in order to reduce noise without available informations}

There are now \Sexpr{dim(clean)[2]} predictors, which will be a little easier to manage with fitting model


%##################################################
\section{Fitting a predictive model}
%##################################################

The model analysis will be\footnote{Source : \url{http://machinelearningmastery.com/evaluate-machine-learning-algorithms-with-r/}} :
\begin{enumerate}[noitemsep]
    \item test variety of models on a small sample of the dataset, with the default tuning. The train will be checked by cross-validation of 10 folds, repeated 3 times, and the distribution of the accuracy, with statistique test, will be reviewed. 
    \item select the bests 5 of them for accuracy, then train and test them with cross-validation on the complete dataset. 
    \item choose the best one.
\end{enumerate}
Further analysis could be to tune the selected model in order to increase performance in accuracy and computation time, but it's not the goal of this report.

\subsection{Global quick review}
The Machine Learning algorithms are choosen to have a good mix of algorithms representations. For this classification case, the \Sexpr{length(fitAll)} models are presented in table~\ref{nameTable}.

<<nameTable, echo=FALSE, results="asis", warning=FALSE, message=FALSE>>=
# print the reviewed model in table.
long <- length(fitAll)
model <- NULL
    # faire avec lapply sur list fitAll ?
    model <- sapply(fitAll, function(x) x[[1]]$modelInfo$label)
    model <- data.frame(model)
# for (i in 1:long){
    # # ligne a changer aprÃ¨s calcul : fitAll[[i]][[1]]$modelInfo$label
    # model <- rbind(model, fitAll[[i]]$modelInfo$label)
# }
print.xtable(xtable(model, caption="Models reviewed",
                    label="nameTable"), include.rownames=FALSE, 
             include.colnames=FALSE, hline.after=c(0,long), 
             table.placement="H")
@

<<plotAllModels, echo=FALSE, cache=TRUE, message=FALSE, out.height="8cm", fig.cap="Accuracy of each model on quickview dataset", fig.pos="h", warning=FALSE>>=
# boxplot all model, oredered by accuracy
library(ggplot2)
plotsAll <- multiSampleAccu(fitAll)
plotsAccu <- multiAccu(fitAll)

library(reshape)
g <- ggplot(data=melt(plotsAll), aes(x=as.factor(variable), y=value)) 
g <- g + geom_boxplot() + theme_minimal()
g <- g + theme(axis.text.x = element_text(angle=30, hjust=1))
g <- g + ylab("Accuracy") + xlab("")
g
@

As seen on figure~\ref{fig:plotAllModels}, the five bests models for accuracy are :
<<nameFive, echo=FALSE, results="asis">>=
nameFive <- data.frame(row.names(plotsAccu[1:5,]))
print.xtable(xtable(nameFive),include.rownames=F, include.colnames=F, 
             hline.after=NULL, table.placement="H")
@
The models have pretty good accuracy, from \Sexpr{round(plotsAccu[1,]$Accuracy, 3)} to \Sexpr{round(plotsAccu[5,]$Accuracy, 3)}. 
The Bagging CART model is especially interesting because of its small computation time, \Sexpr{round(plotsAccu$Time[5],3)} seconds, in comparaison of the \Sexpr{round(plotsAccu$Time[1], 3)} seconds for the C5.0 model.
The statistiques tests for the means are significant, as we fail to reject that the true means is not equal to the samples means, so the samples are representatives of the populations.
The 95\% confidences intervals are presented in table~\ref{confInt}.

<<tTest, echo=FALSE, results="asis">>=
tTest <- apply(plotsAll[,1:5], 2, function(x) t.test(x, mu=mean(x)))
confInt <- sapply(tTest, function(x) x$conf.int)
confInt <- as.data.frame(confInt)
confTable <- matrix(nrow=5, ncol=2)
for (i in 1:5) {
    confTable[i,] <- confInt[,i]
}
row.names(confTable) <- names(plotsAll[,1:5])
print.xtable(xtable(confTable,
                    caption="Confidences intervals for models accuracy",
                    digits=4, label="confInt"), include.colnames=F, 
             hline.after=c(0,nrow(confTable)))
@

\FloatBarrier
\subsection{Best 5 models study}
The 5 bests models will be test on the full dataset, with cross-validation with 10 folders, repeated 3 times.
<<plotFive, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, fig.cap="Accuracy of the five best models on total dataset", out.height="8cm">>=
sampleAccuFive <- multiSampleAccu(fitFive)

g <- ggplot(data=melt(sampleAccuFive), aes(x=as.factor(variable),
                                           y=value)) 
g <- g + geom_boxplot() + theme_minimal()
g <- g + theme(axis.text.x = element_text(angle=30, hjust=1))
g <- g + ylab("Accuracy") + xlab("")
g
@
<<tableFive, echo=FALSE, results="asis">>=
accuTimeFive <- subset(multiAccu(fitFive), select=c(-3))
xtable(accuTimeFive, digits=3, label="tableFive",
       caption="Accuracy and computation time for the 5 bests models")
@
Very very good accuracy, 99\%, with small variations, as seen on the figure~\ref{fig:plotFive}. 
Small decrease of gbm model, which is now worse than the Bagging CART.


%##################################################
\section{And the winner is...}
%##################################################
A good predictive model should be very accurate and very fast. 


All the four finalists models are very accurate, so the difference will be in computation time, and the clear winner is here the \emph{Bagged CART Model}, with only \Sexpr{round(accuTimeFive$Time[4],0)} seconds of computation, in comparaison of \Sexpr{round(accuTimeFive$Time[2],0)} seconds of the \Sexpr{row.names(accuTimeFive[2,])}, which is the slowest model.
The difference appears more clearly on the figure~\ref{fig:plotAccuTimeFive}.

<<plotAccuTimeFive, echo=FALSE, message=FALSE, fig.cap="Accuracy vs computation time", out.height="8cm">>=
accuTimeFive$Accuracy <- accuTimeFive$Accuracy*100
row.names(accuTimeFive[2,])
attach(accuTimeFive)
par(mar=c(4,4,1,1))
plot(Accuracy,Time, xlim=c(95,100.5), ylim=c(0,2300), pch=19, col=c(1:5),
     xlab="Model accuracy (%)", ylab="Computation time (s)") 
text(Accuracy,Time, row.names(accuTimeFive), pos=3) 
detach(accuTimeFive)
@

%------------------------------------------------
\phantomsection
\section*{Acknowledgments} % The \section*{} command stops section numbering

\addcontentsline{toc}{section}{Acknowledgments} % Adds this section to the table of contents
MERCI POUR SITE RAPPORT ET METHODE : METTRE LES SOURCES EN BAS DE PAGE.

So long and thanks for all the fish \cite{Figueredo:2009dg}.

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------
\phantomsection
\bibliographystyle{unsrt}
\bibliography{sample}

%----------------------------------------------------------------------------------------

\clearpage
\appendix
\section{Code}
\subsection{Load Datas}
<<ref.label="loadData", warning=FALSE, eval=FALSE, size="tiny">>=
@

\subsection{Simplify dataset and deal with NAs}

\subsubsection{NA distribution}
<<ref.label="nadist", eval=FALSE, size="tiny">>=
@
<<ref.label="plotna2", eval=FALSE, size="tiny">>=
@

\subsubsection{NA mean}
<<ref.label="namean", eval=FALSE, size="tiny">>=
@
<<ref.label="plotnamean", eval=FALSE, size="tiny">>=
@

\subsection{Fitting a model}

\subsubsection{Model quick review}
<<ref.label="functions", eval=FALSE, size="tiny">>=
@
<<ref.label="testAllModels", eval=FALSE, size="tiny">>=
@
<<ref.label="resultsAllModels", eval=FALSE, size="tiny">>=
@
<<ref.label="nameTable", eval=FALSE, size="tiny">>=
@
<<ref.label="plotAllModels", eval=FALSE, size="tiny">>=
@
<<ref.label="nameFive", eval=FALSE, size="tiny">>=
@
<<ref.label="tTest", eval=FALSE, size="tiny">>=
@
\subsubsection{Best Five models}
<<ref.label="plotFive", eval=FALSE, size="tiny">>=
@
<<ref.label="tableFive", eval=FALSE, size="tiny">>=
@
\subsection{And the Winner is...}
<<ref.label="plotFour", eval=FALSE, size="tiny">>=
@
\end{document}
